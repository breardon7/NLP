# =================================================================
# Class_Ex1:
#  Use the following datframe as the sample data.
# Find the conditional probability of Char given the Occurrence.
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q1' + 20*'-')
import pandas as pd
df = pd.read_csv('data.csv')
print(df.head())
print(df.columns)









print(20*'-' + 'End Q1' + 20*'-')

# =================================================================
# Class_Ex2:
# Use the following datframe as the sample data.
# Find the conditional probability occurrence of thw word given a sentiment.
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q2' + 20*'-')












print(20*'-' + 'End Q2' + 20*'-')
# =================================================================
# Class_Ex3:
# Read the data.csv file.
# Answer the following question
# 1- In this dataset we have a lot of responses in text and each response has a label.
# 2- Our goal is to correctly model the texts into its label.
# Hint: you need to read the text responses and perform preprocessing on it.
# such as normalization, legitimation, cleaning, stopwords removal and POS tagging.
# then use any methods you learned in the lecture to convert each response into meaningful numbers.
# 3- Apply Naive bayes and look at appropriate evaluation metric.
# 4- Explain your results very carefully.
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q3' + 20*'-')
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
df = pd.read_csv('data.csv')
df['cleaned_text'] = ''
#df['vectorized'] =
ps = PorterStemmer()
for i in range(len(df['text'])):
    tokens = word_tokenize(df['text'][i])
    lower = [token.lower() for token in tokens if token.isalnum()]
    no_stop_words = [token for token in lower if token not in stopwords.words('english')]
    stemmed = [ps.stem(token) for token in no_stop_words]
    cleaned_string = ' '.join(stemmed)
    df['cleaned_text'][i] = cleaned_string
corpus = [row for row in df['cleaned_text']]
print(corpus)
print(df.head())






print(20*'-' + 'End Q3' + 20*'-')
# =================================================================
# Class_Ex4:
# Use Naive bayes classifier for this problem,
# Write a text classification pipeline to classify movie reviews as either positive or negative.
# Find a good set of parameters using grid search. hint: grid search on n gram
# Evaluate the performance on a held out test set.
# hint1: use nltk movie reviews dataset
# from nltk.corpus import movie_reviews

# ----------------------------------------------------------------
print(20*'-' + 'Begin Q4' + 20*'-')












print(20*'-' + 'End Q4' + 20*'-')
# =================================================================
# Class_Ex5:
# Calculate accuracy percentage between two lists
# calculate a confusion matrix
# Write your own code - No packages
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q5' + 20*'-')










print(20*'-' + 'End Q5' + 20*'-')
# =================================================================
# Class_Ex6:
# Read the data.csv file.
# Answer the following question
# 1- In this dataset we have a lot of responses in text and each response has a label.
# 2- Our goal is to correctly model the texts into its label.
# Hint: you need to read the text responses and perform preprocessing on it.
# such as normalization, legitimation, cleaning, stopwords removal and POS tagging.
# then use any methods you learned in the lecture to convert each response into meaningful numbers.
# 3- Apply Logistic Regression  and look at appropriate evaluation metric.
# 4- Apply LSA method and compare results.
# 5- Explain your results very carefully.

# ----------------------------------------------------------------
print(20*'-' + 'Begin Q6' + 20*'-')














print(20*'-' + 'End Q6' + 20*'-')

# =================================================================
# Class_Ex7:
# Use logistic regression classifier for this problem,
# Write a text classification pipeline to classify movie reviews as either positive or negative.
# Find a good set of parameters using grid search. hint: grid search on n gram
# Evaluate the performance on a held out test set.
# hint1: use nltk movie reviews dataset
# from nltk.corpus import movie_reviews
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q7' + 20*'-')












print(20*'-' + 'End Q7' + 20*'-')

# =================================================================
# Class_Ex8:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q8' + 20*'-')










print(20*'-' + 'End Q8' + 20*'-')
# =================================================================
# Class_Ex9:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q9' + 20*'-')










print(20*'-' + 'End Q9' + 20*'-')
# =================================================================
# Class_Ex10:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q10' + 20*'-')











print(20*'-' + 'End Q10' + 20*'-')
# =================================================================
# Class_Ex11:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q11' + 20*'-')











print(20*'-' + 'End Q11' + 20*'-')
# =================================================================
# Class_Ex12:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q12' + 20*'-')












print(20*'-' + 'End Q12' + 20*'-')
# =================================================================
# Class_Ex13:
#
# ----------------------------------------------------------------
print(20*'-' + 'Begin Q13' + 20*'-')









print(20*'-' + 'End Q13' + 20*'-')
# =================================================================
# Class_Ex14:
#

# ----------------------------------------------------------------
print(20*'-' + 'Begin Q14' + 20*'-')









print(20*'-' + 'End Q14' + 20*'-')

# =================================================================









